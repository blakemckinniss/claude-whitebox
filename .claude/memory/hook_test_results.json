{
  "timestamp": {
    "total": 89,
    "passing": 34,
    "warnings": 47,
    "failing": 8,
    "failed_hooks": [
      {
        "filename": "performance_reward.py",
        "errors": [
          "Import error: Error: Invalid JSON input: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "pre_write_audit.py",
        "errors": [
          "Import error: Error: Invalid JSON input: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "performance_gate_v1_backup.py",
        "errors": [
          "Import error: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/jinx/workspace/claude-whitebox/.claude/hooks/performance_gate_v1_backup.py\", line 8, in <module>\n    input_data = json.load(sys.stdin)\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "force_playwright.py",
        "errors": [
          "Import error: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/jinx/workspace/claude-whitebox/.claude/hooks/force_playwright.py\", line 13, in <module>\n    data = json.load(sys.stdin)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "post_tool_command_suggester.py",
        "errors": [
          "Import error: Error: Invalid JSON input: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "auto_playwright_setup.py",
        "errors": [
          "Import error: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/jinx/workspace/claude-whitebox/.claude/hooks/auto_playwright_setup.py\", line 14, in <module>\n    data = json.load(sys.stdin)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "meta_cognition_performance.py",
        "errors": [
          "Import error: Error: Invalid JSON input: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "sanity_check.py",
        "errors": [
          "Import error: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/jinx/workspace/claude-whitebox/.claude/hooks/sanity_check.py\", line 10, in <module>\n    data = json.load(sys.stdin)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)"
        ]
      }
    ],
    "warned_hooks": [
      {
        "filename": "hook_performance_monitor.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "performance_analyzer.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_researcher.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "ban_stubs.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "best_practice_enforcer.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "block_mcp.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "pattern_detector.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "evidence_tracker.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "performance_telemetry_collector.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "enforce_workflow.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "command_suggester.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "intervention.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_commit_telemetry.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "ecosystem_mapper.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "confidence_init.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "session_cleanup.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "org_drift_telemetry.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_gaslight.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "trigger_skeptic.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "anti_sycophant.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "command_tracker.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "confidence_gate.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "session_init.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "token_tracker.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "debt_tracker.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "intent_classifier.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_confidence_reward.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "check_knowledge.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "prerequisite_checker.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "tier_gate_v1_backup.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_failure_auto_learn.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_low_confidence.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_success_auto_learn.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "absurdity_detector.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "session_digest.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_commit_on_complete.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "synapse_fire.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "block_main_write.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "risk_gate.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "scratch_flat_enforcer.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_remember.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "command_prerequisite_gate_v1_backup.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_confidence_penalty.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_batch.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_commit_on_end.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_commit_prompt_check.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "root_pollution_gate.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      }
    ]
  },
  "total_hooks": 89,
  "health_summary": {
    "total": 89,
    "passing": 34,
    "warnings": 47,
    "failing": 8,
    "failed_hooks": [
      {
        "filename": "performance_reward.py",
        "errors": [
          "Import error: Error: Invalid JSON input: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "pre_write_audit.py",
        "errors": [
          "Import error: Error: Invalid JSON input: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "performance_gate_v1_backup.py",
        "errors": [
          "Import error: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/jinx/workspace/claude-whitebox/.claude/hooks/performance_gate_v1_backup.py\", line 8, in <module>\n    input_data = json.load(sys.stdin)\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "force_playwright.py",
        "errors": [
          "Import error: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/jinx/workspace/claude-whitebox/.claude/hooks/force_playwright.py\", line 13, in <module>\n    data = json.load(sys.stdin)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "post_tool_command_suggester.py",
        "errors": [
          "Import error: Error: Invalid JSON input: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "auto_playwright_setup.py",
        "errors": [
          "Import error: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/jinx/workspace/claude-whitebox/.claude/hooks/auto_playwright_setup.py\", line 14, in <module>\n    data = json.load(sys.stdin)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "meta_cognition_performance.py",
        "errors": [
          "Import error: Error: Invalid JSON input: Expecting value: line 1 column 1 (char 0)"
        ]
      },
      {
        "filename": "sanity_check.py",
        "errors": [
          "Import error: Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/jinx/workspace/claude-whitebox/.claude/hooks/sanity_check.py\", line 10, in <module>\n    data = json.load(sys.stdin)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)"
        ]
      }
    ],
    "warned_hooks": [
      {
        "filename": "hook_performance_monitor.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "performance_analyzer.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_researcher.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "ban_stubs.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "best_practice_enforcer.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "block_mcp.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "pattern_detector.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "evidence_tracker.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "performance_telemetry_collector.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "enforce_workflow.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "command_suggester.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "intervention.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_commit_telemetry.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "ecosystem_mapper.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "confidence_init.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "session_cleanup.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "org_drift_telemetry.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_gaslight.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "trigger_skeptic.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "anti_sycophant.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "command_tracker.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "confidence_gate.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "session_init.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "token_tracker.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "debt_tracker.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "intent_classifier.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_confidence_reward.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "check_knowledge.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "prerequisite_checker.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "tier_gate_v1_backup.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_failure_auto_learn.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_low_confidence.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_success_auto_learn.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "absurdity_detector.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "session_digest.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_commit_on_complete.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "synapse_fire.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "block_main_write.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "risk_gate.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "scratch_flat_enforcer.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_remember.py",
        "issues": [
          "Missing proper return statement"
        ]
      },
      {
        "filename": "command_prerequisite_gate_v1_backup.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_confidence_penalty.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "detect_batch.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_commit_on_end.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "auto_commit_prompt_check.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      },
      {
        "filename": "root_pollution_gate.py",
        "issues": [
          "Missing main() function",
          "Missing proper return statement"
        ]
      }
    ]
  },
  "execution_results": {
    "assumption_firewall.py": {
      "success": true,
      "duration_ms": 13,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\", \"permissionDecisionReason\": \"No assumption violations detected\"}}\n",
      "stderr": ""
    },
    "hook_performance_monitor.py": {
      "success": true,
      "duration_ms": 17,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "detect_tool_failure.py": {
      "success": true,
      "duration_ms": 26,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "performance_analyzer.py": {
      "success": true,
      "duration_ms": 20,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"SessionStart\", \"additionalContext\": \"\\n\\u26a0\\ufe0f  PERFORMANCE ALERTS (Last 24h):\\n\\ud83d\\udfe1 Tool 'Bash' used 411 times in 24h (possible loop)\\n\\ud83d\\udfe1 Tool 'Read' used 196 times in 24h (possible loop)\\n\\ud83d\\udfe1 Tool 'Edit' used 170 times in 24h (possible loop)\\n\\ud83d\\udfe1 Tool 'Write' used 188 times in 24h (possible loop)\\n\\ud83d\\udfe1 Tool 'TodoWrite' used 119 times in 24h (possible loop)\\n\\ud83d\\udfe1 Tool 'unknown' used 2022 times in 24h (possible loop)\\n\\u2139\\ufe0f 25 sessions in 24h (consider longer sessions)\\n\"}}\n",
      "stderr": ""
    },
    "auto_researcher.py": {
      "success": true,
      "duration_ms": 13,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "ban_stubs.py": {
      "success": true,
      "duration_ms": 13,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\"}}\n",
      "stderr": ""
    },
    "best_practice_enforcer.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "block_mcp.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"deny\", \"permissionDecisionReason\": \"\\u26d4 SYSTEM POLICY: External MCP tool 'Unknown' is BANNED.\\\\nYou must not use black-box tools.\\\\nACTION REQUIRED: Write a script in `scratch/` (e.g., `scratch/tmp_tool.py`), inspect the code, and run it via `Bash`.\"}}\n",
      "stderr": ""
    },
    "pattern_detector.py": {
      "success": true,
      "duration_ms": 21,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "evidence_tracker.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"\\n\\ud83d\\udcc8 EVIDENCE GATHERED: Read (test)\\n   \\u2022 Confidence: 10% \\u2192 12% (+2%)\\n   \\u2022 Current Tier: IGNORANCE\\n\"}}\n",
      "stderr": ""
    },
    "performance_telemetry_collector.py": {
      "success": true,
      "duration_ms": 14,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "enforce_workflow.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"(System Reminder: Prefer writing scratch scripts over manual actions. Check `scratch/` before starting.)\"}}\n",
      "stderr": ""
    },
    "command_suggester.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "intervention.py": {
      "success": true,
      "duration_ms": 18,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "auto_commit_telemetry.py": {
      "success": true,
      "duration_ms": 18,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "ecosystem_mapper.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "detect_parallel_bash.py": {
      "success": true,
      "duration_ms": 14,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"additionalContext\": \"\\n\\u26a1 MULTIPLE BASH OPERATIONS DETECTED (2 calls this turn)\\n\\nYou're executing 2 Bash commands in this response.\\n\\nRECOMMENDATION: Use run_in_background=true for ALL\\n\\nPattern (Single Response):\\n  <invoke name=\\\"Bash\\\">\\n    <parameter name=\\\"command\\\">pytest tests/</parameter>\\n    <parameter name=\\\"run_in_background\\\">true</parameter>\\n  </invoke>\\n  <invoke name=\\\"Bash\\\">\\n    <parameter name=\\\"command\\\">npm run lint</parameter>\\n    <parameter name=\\\"run_in_background\\\">true</parameter>\\n  </invoke>\\n  <invoke name=\\\"Bash\\\">\\n    <parameter name=\\\"command\\\">mypy src/</parameter>\\n    <parameter name=\\\"run_in_background\\\">true</parameter>\\n  </invoke>\\n\\nLater (collect results):\\n  BashOutput(bash_id=\\\"test_shell\\\")\\n  BashOutput(bash_id=\\\"lint_shell\\\")\\n  BashOutput(bash_id=\\\"mypy_shell\\\")\\n\\nBenefits:\\n  \\u2022 2x speedup (parallel execution)\\n  \\u2022 Zero blocking time\\n  \\u2022 Results available on demand\\n\\nNote: Only use if operations are INDEPENDENT.\\n\"}}\n",
      "stderr": ""
    },
    "confidence_init.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "session_cleanup.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "introspector.py": {
      "success": true,
      "duration_ms": 19,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "detect_install.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "enforce_reasoning_rigor.py": {
      "success": true,
      "duration_ms": 15,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"action\": \"allow\"}}\n",
      "stderr": ""
    },
    "org_drift_telemetry.py": {
      "success": true,
      "duration_ms": 14,
      "error": null,
      "stdout": "Success\n",
      "stderr": ""
    },
    "detect_gaslight.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "trigger_skeptic.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "anti_sycophant.py": {
      "success": true,
      "duration_ms": 13,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "command_tracker.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "report_hook_issues.py": {
      "success": true,
      "duration_ms": 16,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"SessionStart\", \"additionalContext\": \"\\u26a0\\ufe0f  HOOK HEALTH CHECK: 8 hook(s) failing\\n\\n  - performance_reward.py: Import error: Error: Invalid JSON input: Expecting value: li\\n  - pre_write_audit.py: Import error: Error: Invalid JSON input: Expecting value: li\\n  - performance_gate_v1_backup.py: Import error: Traceback (most recent call last):\\n\\nRun: python3 scripts/ops/test_hooks.py\\nfor full details.\"}}\n",
      "stderr": ""
    },
    "detect_sequential_agents.py": {
      "success": true,
      "duration_ms": 16,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "detect_logical_fallacy.py": {
      "success": true,
      "duration_ms": 15,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "confidence_gate.py": {
      "success": true,
      "duration_ms": 15,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"deny\", \"permissionDecisionReason\": \"\\n\\ud83d\\udea8 CONFIDENCE GATE: PRODUCTION WRITE BLOCKED\\n\\nCurrent Confidence: 16% (INSUFFICIENT)\\nTarget File: /test\\n\\n\\u26d4 PRODUCTION CODE MODIFICATION REQUIRES 71%+ CONFIDENCE\\n\\nYou are attempting to modify production code without runtime verification.\\n\\nCURRENT TIER: IGNORANCE (0-30%)\\n\\nREQUIRED EVIDENCE FOR 71%+:\\n  1. Read relevant code files (+10% each)\\n  2. Research documentation (/research, +20%)\\n  3. Inspect runtime APIs (/probe, +30%)\\n  4. Verify system state (/verify, +40%)\\n\\nALLOWED RIGHT NOW:\\n  \\u2705 Write to scratch/ (experimentation allowed)\\n  \\u2705 Gather evidence using investigation tools\\n  \\u2705 Test hypotheses in throwaway code\\n\\nFORBIDDEN:\\n  \\u274c Modify scripts/ at <71%\\n  \\u274c Edit production files at <71%\\n  \\u274c Commit unverified changes\\n\\nNEXT STEPS:\\n  1. python3 scripts/ops/confidence.py status (check current state)\\n  2. Gather evidence to reach 71%\\n  3. Retry this operation after threshold met\\n\\n**Earn the right to code. Evidence > Intuition.**\\n\"}}\n",
      "stderr": ""
    },
    "session_init.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "SYSTEM OVERRIDE: EPISTEMOLOGICAL PROTOCOL ACTIVE\n\n\ud83c\udfaf Dual-Metric System Initialized:\n   \u2022 Confidence: 0% (IGNORANCE TIER)\n   \u2022 Risk: 0%\n   \u2022 Session ID: test-ses...\n\n\ud83d\udcca Confidence Tiers:\n   \u2022 IGNORANCE (0-30%): Read/Research/Probe only, no coding\n   \u2022 HYPOTHESIS (31-70%): Can write to scratch/, no production code\n   \u2022 CERTAINTY (71-100%): Full capabilities\n\n\u2696\ufe0f Evidence Gathering Required:\n   \u2022 User Question: +25%\n   \u2022 Web Search: +20%\n   \u2022 Use Scripts: +20%\n   \u2022 Probe API: +15%\n   \u2022 Read File: +10% (first time), +2% (repeat)\n   \u2022 Verify: +15%\n\n\ud83d\udeab Pattern Detection Active:\n   \u2022 Hallucination: -20%\n   \u2022 Falsehood: -25%\n   \u2022 Insanity (repeated failures): -15%\n   \u2022 Tier Violation: -10%\n\nState File: .claude/memory/session_test-session_state.json\n\n",
      "stderr": ""
    },
    "token_tracker.py": {
      "success": true,
      "duration_ms": 24,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "scratch_enforcer.py": {
      "success": true,
      "duration_ms": 16,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "debt_tracker.py": {
      "success": true,
      "duration_ms": 17,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "detect_test_failure.py": {
      "success": true,
      "duration_ms": 26,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "intent_classifier.py": {
      "success": true,
      "duration_ms": 13,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "pre_advice.py": {
      "success": true,
      "duration_ms": 16,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "org_drift_gate.py": {
      "success": true,
      "duration_ms": 26,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\", \"permissionDecisionReason\": \"Organizational drift checks passed\\n\\n\\u26a0\\ufe0f  WARNINGS:\\n  \\u2022 Hook explosion: 89 hooks (threshold: 25). Consider consolidating hooks.\"}}\n",
      "stderr": ""
    },
    "scratch_prompt_analyzer.py": {
      "success": true,
      "duration_ms": 17,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "scratch_enforcer_gate.py": {
      "success": true,
      "duration_ms": 18,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "detect_confidence_reward.py": {
      "success": true,
      "duration_ms": 11,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "check_knowledge.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "prerequisite_checker.py": {
      "success": true,
      "duration_ms": 15,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "batching_telemetry.py": {
      "success": true,
      "duration_ms": 14,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "tier_gate_v1_backup.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"deny\", \"permissionDecisionReason\": \"\\ud83d\\udeab WRITE BLOCKED AT IGNORANCE TIER\\n\\nAction: Write test\\nYour Confidence: 0% (IGNORANCE TIER)\\nRequired: 31%+ (HYPOTHESIS tier)\\n\\nYou know nothing yet. Gather evidence first.\\nAllowed actions: Read, Research, Probe, Ask questions\\n\\nConfidence Penalty: -10%\\n\\nNew Confidence: 0% (IGNORANCE TIER)\\n\\nNext Steps:\\n  1. Gather evidence using allowed tools\\n  2. Build confidence to required tier\\n  3. Then retry this action\\n\"}}\n",
      "stderr": ""
    },
    "detect_failure_auto_learn.py": {
      "success": true,
      "duration_ms": 17,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\"}}",
      "stderr": ""
    },
    "detect_low_confidence.py": {
      "success": true,
      "duration_ms": 15,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "detect_success_auto_learn.py": {
      "success": true,
      "duration_ms": 17,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\"}}\n",
      "stderr": ""
    },
    "constitutional_guard.py": {
      "success": true,
      "duration_ms": 23,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "performance_gate.py": {
      "success": true,
      "duration_ms": 19,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "absurdity_detector.py": {
      "success": true,
      "duration_ms": 14,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "session_digest.py": {
      "success": true,
      "duration_ms": 18,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "auto_commit_on_complete.py": {
      "success": true,
      "duration_ms": 28,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "auto_void.py": {
      "success": true,
      "duration_ms": 24,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "auto_documentarian.py": {
      "success": true,
      "duration_ms": 17,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "synapse_fire.py": {
      "success": true,
      "duration_ms": 19,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "batching_analyzer.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "block_main_write.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "risk_gate.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\"}}\n",
      "stderr": ""
    },
    "background_telemetry.py": {
      "success": true,
      "duration_ms": 14,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "file_operation_gate.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"deny\", \"permissionDecisionReason\": \"\\ud83d\\udeab WRITE BLOCKED: Path outside workspace\\n\\nPath: /test\\n\\nReason: Security violation - cannot write files outside repository.\\n\\n(Use SUDO keyword to bypass)\"}}\n",
      "stderr": ""
    },
    "scratch_flat_enforcer.py": {
      "success": true,
      "duration_ms": 15,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\"}}\n",
      "stderr": ""
    },
    "scratch_context_hook.py": {
      "success": true,
      "duration_ms": 16,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "detect_background_opportunity.py": {
      "success": true,
      "duration_ms": 12,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "native_batching_enforcer_v1_backup.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "hook_documentation_enforcer.py": {
      "success": true,
      "duration_ms": 20,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\"}}\n",
      "stderr": ""
    },
    "tier_gate.py": {
      "success": true,
      "duration_ms": 23,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\"}}\n",
      "stderr": ""
    },
    "pre_delegation.py": {
      "success": true,
      "duration_ms": 14,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\"}}\n",
      "stderr": ""
    },
    "auto_remember.py": {
      "success": true,
      "duration_ms": 14,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "command_prerequisite_gate.py": {
      "success": true,
      "duration_ms": 20,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\"}}\n",
      "stderr": ""
    },
    "command_prerequisite_gate_v1_backup.py": {
      "success": true,
      "duration_ms": 20,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\"}}\n",
      "stderr": ""
    },
    "auto_guardian.py": {
      "success": true,
      "duration_ms": 17,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "detect_confidence_penalty.py": {
      "success": true,
      "duration_ms": 17,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "test_hooks_background.py": {
      "success": true,
      "duration_ms": 19,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"SessionStart\", \"additionalContext\": \"\\ud83e\\uddea Hook test suite running in background...\"}}\n",
      "stderr": ""
    },
    "detect_batch.py": {
      "success": true,
      "duration_ms": 19,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "native_batching_enforcer.py": {
      "success": true,
      "duration_ms": 27,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "auto_commit_on_end.py": {
      "success": true,
      "duration_ms": 18,
      "error": null,
      "stdout": "No uncommitted changes\n",
      "stderr": ""
    },
    "auto_commit_prompt_check.py": {
      "success": true,
      "duration_ms": 21,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"\"}}\n",
      "stderr": ""
    },
    "auto_janitor.py": {
      "success": true,
      "duration_ms": 17,
      "error": null,
      "stdout": "",
      "stderr": ""
    },
    "root_pollution_gate.py": {
      "success": true,
      "duration_ms": 22,
      "error": null,
      "stdout": "{\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"permissionDecision\": \"allow\"}}\n",
      "stderr": ""
    }
  },
  "slow_hooks": [],
  "performance_threshold_ms": 500
}